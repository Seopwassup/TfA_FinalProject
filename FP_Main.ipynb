{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7a9a5c",
   "metadata": {},
   "source": [
    "# Tools for Analytics Final Project ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9229b8",
   "metadata": {},
   "source": [
    "Jaeseop Shin / js6364  &. Hyunjin Jun / hj2642"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff4e23",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4d1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all libraries used for the project\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sodapy import Socrata\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# SQL Data\n",
    "db_username = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a063",
   "metadata": {},
   "source": [
    "## Part 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5cb550",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cf42df",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request.\n\tQuery coordinator error: query.soql.no-such-column; No such column: filter_conditions; position: Map(row -> 1, column -> 8, line -> \"SELECT `filter_conditions` WHERE `filter_conditions` LIMIT 2000\\n       ^\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m select_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_conditions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Data to CSV\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m data_tree \u001b[38;5;241m=\u001b[39m client_tree\u001b[38;5;241m.\u001b[39mget(set_tree, where\u001b[38;5;241m=\u001b[39mwhere_tree, select\u001b[38;5;241m=\u001b[39mselect_tree, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[1;32m     25\u001b[0m df_tree \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(data_tree)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#df_tree.to_csv(\"nyc_tree.csv\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sodapy/socrata.py:412\u001b[0m, in \u001b[0;36mSocrata.get\u001b[0;34m(self, dataset_identifier, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    410\u001b[0m params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mclear_empty_values(params)\n\u001b[0;32m--> 412\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_request(\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, resource, headers\u001b[38;5;241m=\u001b[39mheaders, params\u001b[38;5;241m=\u001b[39mparams\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sodapy/socrata.py:555\u001b[0m, in \u001b[0;36mSocrata._perform_request\u001b[0;34m(self, request_type, resource, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# handle errors\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m202\u001b[39m):\n\u001b[0;32m--> 555\u001b[0m     utils\u001b[38;5;241m.\u001b[39mraise_for_status(response)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# when responses have no content body (ie. delete, set_permission),\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# simply return the whole response\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sodapy/utils.py:30\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m more_info \u001b[38;5;129;01mand\u001b[39;00m more_info\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m response\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     29\u001b[0m     http_error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(more_info)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request.\n\tQuery coordinator error: query.soql.no-such-column; No such column: filter_conditions; position: Map(row -> 1, column -> 8, line -> \"SELECT `filter_conditions` WHERE `filter_conditions` LIMIT 2000\\n       ^\")"
     ]
    }
   ],
   "source": [
    "app_token = \"2Hn2wwabCLXVYhGN4b9tEtJ11\"\n",
    "\n",
    "# Downloading NYC 311 data\n",
    "url_311 = \"data.cityofnewyork.us\"\n",
    "set_311 = \"erm2-nwe9\"\n",
    "client_311 = Socrata(url_311, app_token)\n",
    "client_311.timeout = 60\n",
    "# Filter\n",
    "where_311 = \"date_extract_y(created_date)>=2015\"\n",
    "# Data to CSV\n",
    "data_311 = client_311.get(set_311, where=where_311, limit=2000)\n",
    "df_311 = pd.DataFrame.from_records(data_311)\n",
    "#df_311.to_csv(\"nyc_311.csv\")\n",
    "\n",
    "# Downloading NYC Tree data\n",
    "url_tree = \"data.cityofnewyork.us\"\n",
    "set_tree = \"uvpi-gqnh\"\n",
    "client_tree = Socrata(url_tree, app_token)\n",
    "client_tree.timeout = 60\n",
    "# Filter\n",
    "where_tree = \"filter_conditions\"\n",
    "select_tree = \"filter_conditions\"\n",
    "# Data to CSV\n",
    "data_tree = client_tree.get(set_tree, where=where_tree, select=select_tree, limit=2000)\n",
    "df_tree = pd.DataFrame.from_records(data_tree)\n",
    "#df_tree.to_csv(\"nyc_tree.csv\")\n",
    "\n",
    "\n",
    "rent_path = \"/Users/jin/data/zillow_rent_data.csv\"          # Should be altered by users\n",
    "df_rent = pd.read_csv(rent_path)\n",
    "nyc_zipcodes_shp_path = \"/Users/jin/data/nyc_zipcodes.shp\"       # Should be altered by users\n",
    "gdf_zipcode = gpd.read_file(nyc_zipcodes_shp_path)\n",
    "\n",
    "# Coordiante Reference System\n",
    "CRS = 4326"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c80d59",
   "metadata": {},
   "source": [
    "### Data Cleaning & Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filter(data_frame, column_remove, column_rename, column_type):\n",
    "    \"\"\"Removes unnecessary columns, rename columns, confirm types of columns\"\"\"\n",
    "    data_frame.drop(\"column to remove\", axis=1, inplace=True)\n",
    "    data_frame.rename(columns=column_rename, inplace=True)\n",
    "    for column, dtype in column_type.items():\n",
    "        if dtype == 'datetime64':\n",
    "            data_frame[column] = pd.to_datetime(data_frame[column], errors='coerce')\n",
    "        else:\n",
    "            data_frame[column] = data_frame[column].astype(dtype, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb15269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC 311 Cleaning & Filtering\n",
    "# Columns to remove\n",
    "remove_311 = [\n",
    "    'Closed Date',\n",
    "    'Agency',\n",
    "    'Agency Name',\n",
    "    'Descriptor',\n",
    "    'Location Type',\n",
    "    'Incident Address',\n",
    "    'Street Name',\n",
    "    'Cross Street 1',\n",
    "    'Cross Street 2',\n",
    "    'Intersection Street 1',\n",
    "    'Intersection Street 2',\n",
    "    'Address Type',\n",
    "    'Landmark',\n",
    "    'Facility Type',\n",
    "    'Status',\n",
    "    'Due Date',\n",
    "    'Resolution Description',\n",
    "    'Resolution Action Updated Date',\n",
    "    'Community Board',\n",
    "    'BBL',\n",
    "    'Borough',\n",
    "    'Open Data Channel Type',\n",
    "    'Park Facility Name',\n",
    "    'Park Borough',\n",
    "    'Vehicle Type',\n",
    "    'Taxi Company Borough',\n",
    "    'Taxi Pick Up Location',\n",
    "    'Bridge Highway Name',\n",
    "    'Bridge Highway Direction',\n",
    "    'Road Ramp',\n",
    "    'Bridge Highway Segment'\n",
    "]\n",
    "# Columns to rename\n",
    "rename_311 = {\n",
    "    'Unique Key': 'complaint_id',\n",
    "    'Created Date': 'date',\n",
    "    'Complaint Type': 'complaint_type',\n",
    "    'Incident Zip': 'zipcode',\n",
    "    'City': 'city',\n",
    "    'X Coordinate (State Plane)': 'x_coord',\n",
    "    'Y Coordinate (State Plane)': 'y_coord',\n",
    "    'Latitude': 'latitude',\n",
    "    'Longitude': 'longitude',\n",
    "    'Location': 'geometry'\n",
    "}\n",
    "# Column types\n",
    "type_311 = {\n",
    "    'Unique Key': 'INTEGER',\n",
    "    'Created Date': 'DATETIME',\n",
    "    'Complaint Type': 'TEXT',\n",
    "    'Incident Zip': 'INTEGER',\n",
    "    'City': 'TEXT',\n",
    "    'X Coordinate (State Plane)': 'INTEGER',\n",
    "    'Y Coordinate (State Plane)': 'INTEGER',\n",
    "    'Latitude': 'FLOAT',\n",
    "    'Longitude': 'FLOAT',\n",
    "    'Location': 'TEXT'  #float...?\n",
    "}\n",
    "\n",
    "clean_filter(df_311, remove_311, rename_311, type_311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b195ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC Tree Cleaning & Filtering\n",
    "# Columns to remove\n",
    "remove_tree = [\n",
    "    'created_at',\n",
    "    'block_id',\n",
    "    'tree_dbh',\n",
    "    'stump_diam',\n",
    "    'curb_loc',\n",
    "    'spc_latin',\n",
    "    'steward',\n",
    "    'guards',\n",
    "    'sidewalk',\n",
    "    'user_type',\n",
    "    'problems',\n",
    "    'root_stone',\n",
    "    'root_grate',\n",
    "    'root_other',\n",
    "    'trnk_wire',\n",
    "    'trnk_light',\n",
    "    'trnk_other',\n",
    "    'brnch_ligh',\n",
    "    'brnch_shoe',\n",
    "    'brnch_othe',\n",
    "    'address',   \n",
    "    'cb_num',\n",
    "    'borocode',\n",
    "    'boroname',\n",
    "    'cncldist',\n",
    "    'st_assem',\n",
    "    'st_senate',\n",
    "    'nta',\n",
    "    'nta_name',\n",
    "    'boro_ct',\n",
    "    'state',   \n",
    "]\n",
    "# Columns to rename\n",
    "rename_tree = {\n",
    "    'tree_id': 'tree_id',\n",
    "    'the_geom': 'geometry',\n",
    "    'status': 'status',\n",
    "    'health': 'health',\n",
    "    'spc_common': 'species',\n",
    "    'zipcode': 'zipcode',\n",
    "    'zip_city': 'city',\n",
    "    'Latitude': 'latitude',\n",
    "    'longitude': 'longitude'\n",
    "    'x_sp': 'x_coord',\n",
    "    'y_sp': 'y_coord',\n",
    "}\n",
    "# Column types\n",
    "type_tree = {\n",
    "    'tree_id': 'INTEGER',\n",
    "    'the_geom': 'TEXT',\n",
    "    'status': 'TEXT',\n",
    "    'health': 'TEXT',\n",
    "    'spc_common': 'TEXT',\n",
    "    'zipcode': 'INTEGER',\n",
    "    'zip_city': 'TEXT',\n",
    "    'Latitude': 'FLOAT',\n",
    "    'longitude': 'FLOAT',\n",
    "    'x_sp': 'FLOAT',\n",
    "    'y_sp': 'FLOAT',\n",
    "}\n",
    "\n",
    "clean_filter(df_tree, remove_tree, rename_tree, type_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4bdac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zillow Rent Cleaning & Filtering\n",
    "# Columns to remove\n",
    "remove_rent = [\n",
    "    'RegionID',\n",
    "    'SizeRank',\n",
    "    'RegionType',\n",
    "    'StateName',\n",
    "    'Metro',\n",
    "    'CountyName',\n",
    "]\n",
    "# Columns to rename\n",
    "rename_rent = {\n",
    "    'RegionName': 'zipcode',\n",
    "    'State': 'state',\n",
    "    'City': 'city',\n",
    "}\n",
    "# Column types\n",
    "type_rent = {\n",
    "    'RegionName': 'INTEGER',\n",
    "    'State': 'TEXT',\n",
    "    'city': 'TEXT'\n",
    "}\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "date_cols = pd.date_range('1/31/15', '9/30/23', freq='M')\n",
    "df_rent[date_cols] = df_rent[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Filter out columns between '09/31/2015' and '12/31/2022'\n",
    "date_range_to_remove = pd.date_range('1/31/15', '9/30/22', freq='M')\n",
    "df_rent = df_rent.drop(columns=date_range_to_remove, errors='ignore')\n",
    "\n",
    "clean_filter(df_rent, remove_rent, rename_rent, type_rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f10460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipcode Cleaning & Filtering\n",
    "# Columns to remove\n",
    "remove_gdf = [\n",
    "    'BLDGZIP',\n",
    "    'POPULATION',\n",
    "    'AREA',\n",
    "    'ST_FIPS',\n",
    "    'CTY_FIPS',\n",
    "    'URL',\n",
    "    'SHAPE_AREA',\n",
    "    'SHAPE_LEN',\n",
    "]\n",
    "# Columns to rename\n",
    "rename_gdf = {\n",
    "    'ZIPCODE': 'zipcode',\n",
    "    'PO_NAME': 'city',\n",
    "    'STATE': 'state',\n",
    "    'COUNTY': 'county',\n",
    "    'geometry': 'geometry',\n",
    "}\n",
    "# Column types\n",
    "type_gdf = {\n",
    "    'ZIPCODE': 'INTEGER',\n",
    "    'PO_NAME': 'TEXT',\n",
    "    'STATE': 'TEXT',\n",
    "    'COUNTY': 'TEXT',\n",
    "    'geometry': 'TEXT',\n",
    "}\n",
    "\n",
    "clean_filter(gdf_zipcode, remove_gdf, rename_gdf, type_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5afe80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
